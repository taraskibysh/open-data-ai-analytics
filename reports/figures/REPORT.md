# Звіт з лабораторної роботи №1

## 1. Мета роботи
Опанувати повний цикл розвідувального аналізу даних (EDA), починаючи від завантаження та очищення "сирих" даних, закінчуючи побудовою візуалізацій, перевіркою бізнес-гіпотез та оформленням проєкту згідно з кращими практиками розробки (Git, модульна структура).

## 2. Структура проєкту
Під час виконання роботи було налаштовано професійну файлову структуру:
* `data/` — директорія для зберігання вхідних даних.
* `src/` — містить Python-скрипти.
* `notebooks/` — Jupyter-блокноти з поетапним аналізом.
* `reports/figures/` — директорія для збереження графіків.
* `tests/` - директорія що містить тести проекту.
* `.github/workflows` - директорія для збереження github пайплайнів. 
* Конфігураційні файли: `.gitignore`, `CHANGELOG.md`, `README.md`.


## 3. Етапи виконання роботи

### Етап 1: Підготовка та очищення даних (`feature/eda-notebook`)
* Реалізовано окремий скрипт для зчитування Excel-файлу.
* Проведено первинний аналіз датасету та виведено базову статистичну інформацію.

### Етап 2: Налаштування пайплайну (`feature/ci-pipeline`)
* Налаштовано CI-пайплайн для автоматичної збірки проєкту та запуску тестів при створенні pull request, а також при мерджі в гілку main.

### Етап 3: Навчання моделі (`feature/data_research`)
* Проведено дослідження даних та навчено модель на підготовленому датасеті.
* Виконано аналіз аномалій.
* Результати збережено у зовнішні файли.

### Етап 4: Візуалізація даних (`feature/visualization`)
* Побудовано базові графіки для аналізу та дослідження результатів.

## 4. Робота з системою контролю версій (Git)
Усі етапи розробки були логічно розділені за допомогою Git:
* Кожна задача виконувалася в ізольованій гілці (наприклад, `feature/data_load`, `feature/data_research`).
* Зміни зливалися через Pull Requests з описом виконаної роботи.
* Для фіксації першої стабільної версії аналізу створено файл `CHANGELOG.md` та додано Git-тег `v0.1.0`.